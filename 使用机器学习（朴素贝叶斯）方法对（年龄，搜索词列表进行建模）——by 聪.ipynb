{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 基于自然语言处理的搜索引擎公司用户画像——使用机器学习（朴素贝叶斯）方法对（年龄，搜索词列表进行建模）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集：\n",
    "|数据文件|\t备注|\n",
    "|----  | ----  |\n",
    "|train.csv|\t带标注的训练集|\n",
    "|test.csv|\t测试集|\n",
    "\n",
    "# 数据介绍\n",
    "本数据来源于真实搜索引擎数据，ID经过加密，训练集中人口属性数据存在部分未知的情况。数据所有字段如下表所示：\n",
    "\n",
    "|字段|\t说明|\n",
    "|----  | ----  |\n",
    "|ID\t加密后的ID|\n",
    "|Age|\t0：未知年龄; 1：0-18岁; 2：19-23岁; 3：24-30岁; 4：31-40岁; 5：41-50岁; 6： 51-999岁|\n",
    "|Gender|\t0：未知1：男性2：女性|\n",
    "|Education|\t0：未知学历; 1：博士; 2：硕士; 3：大学生; 4：高中; 5：初中; 6：小学|\n",
    "|Query List|\t搜索词列表|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据一览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import jieba    #分词包\n",
    "import numpy    #numpy计算包\n",
    "import codecs   #codecs提供的open方法来指定打开的文件的语言编码，它会在读取的时候自动转换为内部unicode \n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"./data/train.csv\", sep=\"###__###\",header = None,encoding='utf-8')\n",
    "test = pd.read_csv(\"./data/test.csv\", sep=\"###__###\",header = None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Query_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22DD920316420BE2DF8D6EE651BA174B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>柔和双沟\\t女生\\t中财网首页 财经\\thttp://pan.baidu.com/s/1pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43CC3AF5A8D6430A3B572337A889AFE4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>广州厨宝烤箱\\t世情薄,人情恶,雨送黄昏花易落,晓风干,泪痕\\t厦门酒店用品批发市场\\t我只...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E97654BFF5570E2CCD433EA6128EAC19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>钻石之泪耳机\\t盘锦到沈阳\\t旅顺公交\\t辽宁阜新车牌\\tbaidu\\tk715\\tk716...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6931EFC26D229CCFCEA125D3F3C21E57</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>最受欢迎狗狗排行榜\\t舶怎么读\\t场景描 写范例\\t三维绘图软件\\t枣和酸奶能一起吃吗\\t好...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E780470C3BB0D340334BD08CDCC3C71A</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>干槽症能自愈吗\\t太太万岁叶舒心去没去美国\\t干槽症\\t右眼皮下面一直跳是怎么回事\\t麦当劳...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  Age  Gender  Education  \\\n",
       "0  22DD920316420BE2DF8D6EE651BA174B    1       1          4   \n",
       "1  43CC3AF5A8D6430A3B572337A889AFE4    2       1          3   \n",
       "2  E97654BFF5570E2CCD433EA6128EAC19    4       1          0   \n",
       "3  6931EFC26D229CCFCEA125D3F3C21E57    4       2          3   \n",
       "4  E780470C3BB0D340334BD08CDCC3C71A    2       2          4   \n",
       "\n",
       "                                          Query_List  \n",
       "0  柔和双沟\\t女生\\t中财网首页 财经\\thttp://pan.baidu.com/s/1pl...  \n",
       "1  广州厨宝烤箱\\t世情薄,人情恶,雨送黄昏花易落,晓风干,泪痕\\t厦门酒店用品批发市场\\t我只...  \n",
       "2  钻石之泪耳机\\t盘锦到沈阳\\t旅顺公交\\t辽宁阜新车牌\\tbaidu\\tk715\\tk716...  \n",
       "3  最受欢迎狗狗排行榜\\t舶怎么读\\t场景描 写范例\\t三维绘图软件\\t枣和酸奶能一起吃吗\\t好...  \n",
       "4  干槽症能自愈吗\\t太太万岁叶舒心去没去美国\\t干槽症\\t右眼皮下面一直跳是怎么回事\\t麦当劳...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns = ['ID', 'Age', 'Gender', 'Education', 'Query_List']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Query_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ED89D43B9F602F96D96C25255F7C228C</td>\n",
       "      <td>陈学冬将出的作品\\t刘昊然与谭松韵\\t211学校的分数线\\t谁唱的味道好听\\t吻戏是真吻还是...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83C3B7B4AAF8074655A8079F561A76D6</td>\n",
       "      <td>e的0.0052次方\\tqq怎么快速提现\\t绝色倾城飞烟\\t马克思主义基本原理概论\\t康世恩...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA9F675A024FB2353849350A35CF8B0F</td>\n",
       "      <td>黑暗文\\tlpl夏季赛\\t大富豪电玩城\\t英雄联盟之电竞称王\\t手机怎么扫描手机上的二维码\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE45B5C4E57AAEBCF3FDFA2A774093BF</td>\n",
       "      <td>中秋水库钓鱼\\t鱼竿\\t用蚯蚓钓鱼怎样调漂\\t传统钓\\t3号鱼钩\\t鲫鱼汤的做法大全\\t鱼饵...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>406A681FB3DF81EC0E561796AE50AE50</td>\n",
       "      <td>号码吉凶\\t退休干部死后配偶\\t郫县有哪些大学\\t胜利油田属于中石化还是中石油\\t苏珊米勒狮...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  \\\n",
       "0  ED89D43B9F602F96D96C25255F7C228C   \n",
       "1  83C3B7B4AAF8074655A8079F561A76D6   \n",
       "2  CA9F675A024FB2353849350A35CF8B0F   \n",
       "3  DE45B5C4E57AAEBCF3FDFA2A774093BF   \n",
       "4  406A681FB3DF81EC0E561796AE50AE50   \n",
       "\n",
       "                                          Query_List  \n",
       "0  陈学冬将出的作品\\t刘昊然与谭松韵\\t211学校的分数线\\t谁唱的味道好听\\t吻戏是真吻还是...  \n",
       "1  e的0.0052次方\\tqq怎么快速提现\\t绝色倾城飞烟\\t马克思主义基本原理概论\\t康世恩...  \n",
       "2  黑暗文\\tlpl夏季赛\\t大富豪电玩城\\t英雄联盟之电竞称王\\t手机怎么扫描手机上的二维码\\...  \n",
       "3  中秋水库钓鱼\\t鱼竿\\t用蚯蚓钓鱼怎样调漂\\t传统钓\\t3号鱼钩\\t鲫鱼汤的做法大全\\t鱼饵...  \n",
       "4  号码吉凶\\t退休干部死后配偶\\t郫县有哪些大学\\t胜利油田属于中石化还是中石油\\t苏珊米勒狮...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns = ['ID', 'Query_List']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   ID          100000 non-null  object\n",
      " 1   Age         100000 non-null  int64 \n",
      " 2   Gender      100000 non-null  int64 \n",
      " 3   Education   100000 non-null  int64 \n",
      " 4   Query_List  100000 non-null  object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   ID          100000 non-null  object\n",
      " 1   Query_List  100000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Query_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>柔和双沟\\t女生\\t中财网首页 财经\\thttp://pan.baidu.com/s/1pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>广州厨宝烤箱\\t世情薄,人情恶,雨送黄昏花易落,晓风干,泪痕\\t厦门酒店用品批发市场\\t我只...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>钻石之泪耳机\\t盘锦到沈阳\\t旅顺公交\\t辽宁阜新车牌\\tbaidu\\tk715\\tk716...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>最受欢迎狗狗排行榜\\t舶怎么读\\t场景描 写范例\\t三维绘图软件\\t枣和酸奶能一起吃吗\\t好...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>干槽症能自愈吗\\t太太万岁叶舒心去没去美国\\t干槽症\\t右眼皮下面一直跳是怎么回事\\t麦当劳...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age                                         Query_List\n",
       "0    1  柔和双沟\\t女生\\t中财网首页 财经\\thttp://pan.baidu.com/s/1pl...\n",
       "1    2  广州厨宝烤箱\\t世情薄,人情恶,雨送黄昏花易落,晓风干,泪痕\\t厦门酒店用品批发市场\\t我只...\n",
       "2    4  钻石之泪耳机\\t盘锦到沈阳\\t旅顺公交\\t辽宁阜新车牌\\tbaidu\\tk715\\tk716...\n",
       "3    4  最受欢迎狗狗排行榜\\t舶怎么读\\t场景描 写范例\\t三维绘图软件\\t枣和酸奶能一起吃吗\\t好...\n",
       "4    2  干槽症能自愈吗\\t太太万岁叶舒心去没去美国\\t干槽症\\t右眼皮下面一直跳是怎么回事\\t麦当劳..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_age = train.loc[(train['Age']!=0),['Age','Query_List']]\n",
    "train_age.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jieba分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将每个年龄段的数据转换成列表\n",
    "train_age1 = train_age.loc[(train['Age']==1),['Age','Query_List']]\n",
    "train_age1 = train_age1.Query_List.values.tolist()\n",
    "train_age2 = train_age.loc[(train['Age']==2),['Age','Query_List']]\n",
    "train_age2 = train_age2.Query_List.values.tolist()\n",
    "train_age3 = train_age.loc[(train['Age']==3),['Age','Query_List']]\n",
    "train_age3 = train_age3.Query_List.values.tolist()\n",
    "train_age4 = train_age.loc[(train['Age']==4),['Age','Query_List']]\n",
    "train_age4 = train_age4.Query_List.values.tolist()\n",
    "train_age5 = train_age.loc[(train['Age']==5),['Age','Query_List']]\n",
    "train_age5 = train_age5.Query_List.values.tolist()\n",
    "train_age6 = train_age.loc[(train['Age']==6),['Age','Query_List']]\n",
    "train_age6 = train_age6.Query_List.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停用词\n",
    "stopwords=pd.read_csv(\"./stopwords-master/cn_stopwords.txt\",index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "stopwords=stopwords['stopword'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\15243\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.952 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 去停用词\n",
    "def preprocess_text(content_lines, sentences, category, target_path):\n",
    "    for line in content_lines:\n",
    "        try:\n",
    "            segs=jieba.lcut(line)\n",
    "            segs = list(filter(lambda x:len(x)>1, segs)) #没有解析出来的过滤掉\n",
    "            segs = list(filter(lambda x:x not in stopwords, segs)) #把停用词过滤掉\n",
    "            sentences.append((\" \".join(segs), category))\n",
    "        except Exception as e:\n",
    "            print(line)\n",
    "            continue\n",
    "\n",
    "#生成训练数据\n",
    "sentences = []\n",
    "preprocess_text(train_age1, sentences, 1, '../data/data')\n",
    "preprocess_text(train_age2, sentences, 2, '../data/data')\n",
    "preprocess_text(train_age3, sentences, 3, '../data/data')\n",
    "preprocess_text(train_age4, sentences, 4, '../data/data')\n",
    "preprocess_text(train_age5, sentences, 5, '../data/data')\n",
    "preprocess_text(train_age6, sentences, 6, '../data/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打乱顺序\n",
    "import random\n",
    "random.shuffle(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, y = zip(*sentences)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽取n-gram统计特征\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(\n",
    "    analyzer='word', # tokenise by character ngrams\n",
    "    ngram_range=(1,4),  # use ngrams of size 1, 2, 3, 4\n",
    "    max_features=20000,  # keep the most common 2000 ngrams\n",
    ")\n",
    "vec.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import numpy as np\n",
    "\n",
    "def stratifiedkfold_cv(x, y, clf_class, shuffle=True, n_folds=5, **kwargs):\n",
    "    stratifiedk_fold = StratifiedKFold(n_splits=n_folds, shuffle=shuffle)\n",
    "    y_pred = y[:]\n",
    "    for x,train_inde,test_index in stratifiedk_fold.split(x, y):\n",
    "        X_train, X_test = x[train_index], x[test_index]\n",
    "        y_train = y[train_index]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "    return y_pred \n",
    "\n",
    "NB = MultinomialNB\n",
    "print(precision_score(y, stratifiedkfold_cv(vec.transform(x),np.array(y),NB), average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
